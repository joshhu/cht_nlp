{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora import WikiCorpus\n",
    "\n",
    "wiki_corpus = WikiCorpus('zhwiki-20200301-pages-articles-multistream.xml.bz2', dictionary={})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['歐幾里得',\n",
       " '西元前三世紀的古希臘數學家',\n",
       " '現在被認為是幾何之父',\n",
       " '此畫為拉斐爾的作品',\n",
       " '雅典學院',\n",
       " '数学',\n",
       " '是利用符号语言研究數量',\n",
       " '结构',\n",
       " '变化以及空间等概念的一門学科',\n",
       " '从某种角度看屬於形式科學的一種']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(wiki_corpus.get_texts()))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 articles processed.\n",
      "20000 articles processed.\n",
      "30000 articles processed.\n",
      "40000 articles processed.\n",
      "50000 articles processed.\n",
      "60000 articles processed.\n",
      "70000 articles processed.\n",
      "80000 articles processed.\n",
      "90000 articles processed.\n",
      "100000 articles processed.\n",
      "110000 articles processed.\n",
      "120000 articles processed.\n",
      "130000 articles processed.\n",
      "140000 articles processed.\n",
      "150000 articles processed.\n",
      "160000 articles processed.\n",
      "170000 articles processed.\n",
      "180000 articles processed.\n",
      "190000 articles processed.\n",
      "200000 articles processed.\n",
      "210000 articles processed.\n",
      "220000 articles processed.\n",
      "230000 articles processed.\n",
      "240000 articles processed.\n",
      "250000 articles processed.\n",
      "260000 articles processed.\n",
      "270000 articles processed.\n",
      "280000 articles processed.\n",
      "290000 articles processed.\n",
      "300000 articles processed.\n",
      "310000 articles processed.\n",
      "320000 articles processed.\n",
      "330000 articles processed.\n",
      "340000 articles processed.\n",
      "350000 articles processed.\n",
      "356901 articles processed.\n"
     ]
    }
   ],
   "source": [
    "text_num = 0\n",
    "\n",
    "with open('wiki_text.txt', 'w', encoding='utf-8') as f:\n",
    "    for text in wiki_corpus.get_texts():\n",
    "        f.write(' '.join(text)+'\\n')\n",
    "        text_num += 1\n",
    "        if text_num % 10000 == 0:\n",
    "            print('{} articles processed.'.format(text_num))\n",
    "\n",
    "    print('{} articles processed.'.format(text_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencc-python-reimplemented in /home/joshhu/.conda/envs/pytorch13/lib/python3.7/site-packages (0.1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencc-python-reimplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.551 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "841999011"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "from opencc import OpenCC\n",
    "\n",
    "\n",
    "# Initial\n",
    "cc = OpenCC('s2t')\n",
    "train_data = open('wiki_text.txt', 'r', encoding='utf-8').read()\n",
    "train_data = cc.convert(train_data)\n",
    "train_data = jieba.lcut(train_data)\n",
    "train_data = [word for word in train_data if word != '']\n",
    "train_data = ' '.join(train_data)\n",
    "open('seg.txt', 'w', encoding='utf-8').write(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "\n",
    "# Settings\n",
    "seed = 666\n",
    "sg = 0\n",
    "window_size = 10\n",
    "vector_size = 100\n",
    "min_count = 1\n",
    "workers = 8\n",
    "epochs = 5\n",
    "batch_words = 10000\n",
    "\n",
    "train_data = word2vec.LineSentence('seg.txt')\n",
    "model = word2vec.Word2Vec(\n",
    "    train_data,\n",
    "    min_count=min_count,\n",
    "    size=vector_size,\n",
    "    workers=workers,\n",
    "    iter=epochs,\n",
    "    window=window_size,\n",
    "    sg=sg,\n",
    "    seed=seed,\n",
    "    batch_words=batch_words\n",
    ")\n",
    "\n",
    "model.save('word2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "微生物\n",
      "('細菌', 0.8547828197479248)\n",
      "('毒理', 0.8070753812789917)\n",
      "('厭氧', 0.7949184775352478)\n",
      "('菌種', 0.7802312970161438)\n",
      "('生物', 0.7761634588241577)\n",
      "('病原菌', 0.7692522406578064)\n",
      "('病菌', 0.769157886505127)\n",
      "('呼吸作用', 0.7668559551239014)\n",
      "('謝產物', 0.7663991451263428)\n",
      "('化學物質', 0.7659590840339661)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "string = '微生物'\n",
    "model = word2vec.Word2Vec.load('word2vec.model')\n",
    "print(string)\n",
    "\n",
    "for item in model.wv.most_similar(string):\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:general]",
   "language": "python",
   "name": "conda-env-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
